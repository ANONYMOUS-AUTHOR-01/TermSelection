{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MetaOCC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mac3rrXU_bBw",
        "DF7d3jZf_ke9",
        "UR3x_sfn_8Fu"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pIkb6K9erh"
      },
      "source": [
        "!pip install -r mta_requirements.txt &> /dev/null\n",
        "!pip install --upgrade scikit-learn &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An422zP-M-XD"
      },
      "source": [
        "from modules.utils import *\n",
        "refset_iri_dir = 'data/SnomedCT/nrc_refset_iri/'\n",
        "refset_embed_dir = 'data/SnomedCT/refset_embed/'\n",
        "embed_path = 'data/SnomedCT/concept_embedding.csv'\n",
        "iri_path = 'data/SnomedCT/concept_iri.csv'\n",
        "seed_path = 'data/SnomedCT/nrc_seed_random_iri/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mac3rrXU_bBw"
      },
      "source": [
        "## Define Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2KUCgAl_d8u"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from qpth.qp import QPFunction\n",
        "\n",
        "\n",
        "class SVDDLayer(nn.Module):\n",
        "    def __init__(self, shot, dim=1, eps=1e-6):\n",
        "        super(SVDDLayer, self).__init__()\n",
        "        self._dim = dim\n",
        "        self._eps = eps\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        shot = inputs.shape[1]\n",
        "\n",
        "        kernel_matrices = torch.bmm(inputs, inputs.transpose(1, 2))\n",
        "        kernel_matrices += self._eps * torch.eye(shot)\n",
        "        kernel_diags = torch.diagonal(kernel_matrices, dim1=-2, dim2=-1)\n",
        "        Q = 2 * kernel_matrices\n",
        "        p = -kernel_diags\n",
        "        A = torch.ones(1, shot)\n",
        "        b = torch.ones(1)\n",
        "        G = -torch.eye(shot)\n",
        "        h = torch.zeros(shot)\n",
        "        alphas = QPFunction(verbose=-1)(\n",
        "            Q,\n",
        "            p,\n",
        "            G.detach(),\n",
        "            h.detach(),\n",
        "            A.detach(),\n",
        "            b.detach(),\n",
        "        )\n",
        "\n",
        "        alphas = alphas.unsqueeze(-1)\n",
        "        centers = torch.sum(alphas * inputs, dim=self._dim)\n",
        "\n",
        "        return centers\n",
        "\n",
        "\n",
        "class CentersDistance(nn.Module):\n",
        "    def __init__(self, dim=-1):\n",
        "        super(CentersDistance, self).__init__()\n",
        "        self._dim = dim\n",
        "\n",
        "    def forward(self, inputs, centers):\n",
        "        logits = -torch.sum((centers.unsqueeze(1) - inputs)**2, dim=self._dim)\n",
        "        return logits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF7d3jZf_ke9"
      },
      "source": [
        "## Define Modle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8lNzFve_nLl"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class EmbeddingNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 hidden_size: int = 64) -> None:\n",
        "        super(EmbeddingNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(200, 200),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        reshaped = inputs.reshape(-1, *inputs.shape[2:])\n",
        "        embeddings = self.net(reshaped)\n",
        "        outputs = embeddings.view(*inputs.shape[:2], -1)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class MetaOCCModel(nn.Module):\n",
        "    def __init__(self, embedding_net, occ_layer):\n",
        "        super(MetaOCCModel, self).__init__()\n",
        "        self._embedding_net = embedding_net\n",
        "        self._net = nn.Sequential(embedding_net, occ_layer)\n",
        "        self._to_logits = CentersDistance()\n",
        "\n",
        "    def forward(self, support_inputs, query_inputs):\n",
        "        centers = self._net(support_inputs)\n",
        "        query_embeddings = self._embedding_net(query_inputs)\n",
        "        logits = self._to_logits(query_embeddings, centers)\n",
        "        return logits\n",
        "\n",
        "    def infer(self, support_inputs, query_inputs):\n",
        "        logits = self(support_inputs, query_inputs)\n",
        "        probs = 1.0 + torch.tanh(logits)\n",
        "        return probs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR3x_sfn_8Fu"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLEMyAfa_6bG"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def evaluate(model, loader, total_episodes, shot, device=None):\n",
        "    accs = []\n",
        "    while len(accs) < total_episodes:\n",
        "        (support_inputs, query_inputs,\n",
        "          query_labels) = loader.get_train_data(True)\n",
        "\n",
        "        if device:\n",
        "            support_inputs = support_inputs.to(device=device)\n",
        "            query_inputs = query_inputs.to(device=device)\n",
        "            query_labels = query_labels.to(device=device)\n",
        "\n",
        "        probs = model.infer(support_inputs, query_inputs)\n",
        "        preds = (probs >= 0.5).long()\n",
        "        correct = preds.eq(query_labels)\n",
        "        batch_accs = torch.mean(correct.float(),\n",
        "                                dim=1).detach().cpu().numpy()\n",
        "\n",
        "        episodes_so_far = len(accs)\n",
        "        if episodes_so_far + len(batch_accs) < total_episodes:\n",
        "            accs.extend(batch_accs)\n",
        "        else:\n",
        "            rem = total_episodes - episodes_so_far\n",
        "            accs.extend(batch_accs[:rem])\n",
        "            break\n",
        "\n",
        "    mean = np.mean(accs)\n",
        "    std = np.std(accs)\n",
        "    ci95 = 1.96 * std / np.sqrt(len(accs))\n",
        "\n",
        "    return mean, ci95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBVjzFMBAqyt"
      },
      "source": [
        "## Other utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbejv6oHAtDs"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from  sklearn.metrics import ndcg_score, roc_auc_score\n",
        "\n",
        "def get_refset_name(raw_name):\n",
        "    name = raw_name.split(\"Active\")[0].split('_')[-1]\n",
        "    return name\n",
        "\n",
        "class my_Data_Loader(object):\n",
        "  def __init__(self, refset_iri_dir, refset_embed_dir, embed_path, iri_path):\n",
        "    self.rnd = np.random.RandomState(42)\n",
        "    self.fname_list = os.listdir(refset_iri_dir)\n",
        "    size = len(self.fname_list)\n",
        "    shuffled_idx = self.rnd.permutation(range(size))\n",
        "    self.train_idx = shuffled_idx[:int(size * 0.8)]\n",
        "    self.test_idx = shuffled_idx[int(size * 0.8):]\n",
        "\n",
        "    self.refset_embeds = [np.loadtxt(refset_embed_dir + fname) for fname in self.fname_list]\n",
        "    self.refset_iris = [np.loadtxt(refset_iri_dir + fname, dtype='str') for fname in self.fname_list]\n",
        "    self.embeds = np.loadtxt(embed_path)\n",
        "    # self.embeds = self.refset_embeds[0]\n",
        "    self.iris = np.loadtxt(iri_path, dtype=str)\n",
        "    self.iri2idx = dict()\n",
        "    for index, iri in enumerate(self.iris):\n",
        "      self.iri2idx[iri] = index\n",
        "    \n",
        "    print(\"Loading done!\")\n",
        "  def reset(self, seed=42):\n",
        "    self.rnd = np.random.RandomState(seed)\n",
        "  \n",
        "  def set_test_idx(self, test_idx):\n",
        "    size = len(self.fname_list)\n",
        "    assert test_idx < size\n",
        "\n",
        "    shot = 5\n",
        "\n",
        "    self.test_idx = test_idx\n",
        "    self.train_idx = [i for i in range(size)]\n",
        "    self.train_idx.pop(test_idx)\n",
        "\n",
        "    fname = self.fname_list[self.test_idx]\n",
        "    seed_iris = np.loadtxt(seed_path + fname, dtype=str)\n",
        "    seed_embeds = []\n",
        "    for item in seed_iris:\n",
        "      seed_embeds.append(self.embeds[self.iri2idx[item]])\n",
        "    \n",
        "    self.support_inputs = torch.tensor([[[item] for item in seed_embeds[:shot]]], dtype=torch.float32) \n",
        "    self.query_inputs = torch.tensor([[[item] for item in self.embeds]], dtype=torch.float32)\n",
        "    \n",
        "    tmp_list = np.zeros(shape=len(self.embeds))\n",
        "    for item in self.refset_iris[test_idx]:\n",
        "      tmp_list[self.iri2idx[item]] = 1\n",
        "    self.query_outputs = np.array([tmp_list])\n",
        "\n",
        "\n",
        "  def get_train_data(self, is_val=False):\n",
        "    batch_size = 8\n",
        "\n",
        "    support_inputs = []\n",
        "    query_inputs = []\n",
        "    query_outputs = []\n",
        "\n",
        "    batch_idx = self.rnd.permutation(self.train_idx)[:batch_size]\n",
        "    refset_sizes = [int(len(self.refset_embeds[idx])/2) for idx in batch_idx]\n",
        "    shot = min(min(refset_sizes), 256)\n",
        "\n",
        "    for idx in range(batch_size):\n",
        "\n",
        "      sample_idx = batch_idx[idx]\n",
        "    \n",
        "      this_refset_embeds = self.rnd.permutation(self.refset_embeds[sample_idx])\n",
        "\n",
        "      support_inputs.append(\n",
        "          [[item] for item in this_refset_embeds[:shot]]\n",
        "      )\n",
        "\n",
        "      query_inputs.append(\n",
        "          [[item] for item in this_refset_embeds[shot:2 * shot]]\n",
        "      )\n",
        "      \n",
        "      tmp_list = []\n",
        "      for _idx in self.rnd.permutation(len(self.embeds)):\n",
        "        if self.iris[_idx] in self.refset_iris[sample_idx]:\n",
        "          continue\n",
        "        else:\n",
        "          tmp_list.append([self.embeds[_idx]])\n",
        "          if len(tmp_list) >= shot:\n",
        "            break\n",
        "      query_inputs[-1].extend(tmp_list)\n",
        "      \n",
        "      query_outputs.append([1 if _ < shot else 0 for _ in range(2 * shot)])\n",
        "    \n",
        "    return torch.tensor(support_inputs,dtype=torch.float32), torch.tensor(query_inputs,dtype=torch.float32), torch.tensor(query_outputs,dtype=torch.long)\n",
        "\n",
        "  def get_test_data(self):\n",
        "    return self.support_inputs, self.query_inputs, self.query_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwmEklP4-NxA"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjvD_W3tDML8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4943be96-a946-482f-e11a-7c941a768817"
      },
      "source": [
        "mdl = my_Data_Loader(refset_iri_dir, refset_embed_dir, embed_path, iri_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ5Fx9pCzxvy"
      },
      "source": [
        "f = open('./select_nrc.txt', 'a+')\n",
        "def run(test_idx):\n",
        "  mdl.set_test_idx(test_idx)\n",
        "  device = torch.device('cpu')\n",
        "  mdl.reset(42)\n",
        "\n",
        "  layer = SVDDLayer(5)\n",
        "\n",
        "\n",
        "  model = MetaOCCModel(EmbeddingNet(200, 200), layer)\n",
        "  model.to(device)\n",
        "  loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=4e-5, weight_decay=0.01)\n",
        "\n",
        "  step = 0\n",
        "  best_lb = 0.\n",
        "  best_mean = 0.\n",
        "  faults = 0\n",
        "  while step <= 300:\n",
        "    (support_inputs, query_inputs,\n",
        "      query_labels) = mdl.get_train_data()\n",
        "\n",
        "    support_inputs = support_inputs.to(device)\n",
        "    query_inputs = query_inputs.to(device)\n",
        "    query_labels = query_labels.to(device)\n",
        "\n",
        "    # print(support_inputs.shape)\n",
        "\n",
        "    try:\n",
        "      loss_val = loss(model(support_inputs, query_inputs), query_labels.float())\n",
        "    except Exception as e:\n",
        "      continue\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_val.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        pass\n",
        "        # print(f'Step {step}, loss = {loss_val.item()}')\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        model.train(False)\n",
        "        (support_inputs, query_inputs, query_labels) = mdl.get_test_data()\n",
        "        \n",
        "\n",
        "        support_inputs = support_inputs.to(device)\n",
        "        query_inputs = query_inputs.to(device)\n",
        "\n",
        "        probs = model.infer(support_inputs, query_inputs).detach().numpy()\n",
        "        model.train(True)\n",
        "\n",
        "        y_pred = np.zeros(shape=354256)\n",
        "        counter = 0.0\n",
        "        for index in np.argsort(probs[0]):\n",
        "          y_pred[index] = 1 - counter / 354256\n",
        "          counter += 1\n",
        "        probs = [y_pred]\n",
        "\n",
        "        refset_name = mdl.fname_list[test_idx]\n",
        "        ndcg = ndcg_score([query_labels[0]], [probs[0]])\n",
        "        auc = roc_auc_score(query_labels[0], probs[0])\n",
        "\n",
        "        y_pred = np.zeros(shape=354256)\n",
        "        counter = 0.0\n",
        "        for index in np.argsort(probs[0]):\n",
        "          y_pred[index] = 1 - counter / 354256\n",
        "          counter += 1\n",
        "        probs = [y_pred]\n",
        "\n",
        "        new_ndcg = ndcg_score([query_labels[0]], [probs[0]])\n",
        "        new_auc = roc_auc_score(query_labels[0], probs[0])\n",
        "\n",
        "        st = \"refset={:35s} training_iter={} meta_occ score: NDCG={:.4f} AUC={:.4f}\".format(refset_name, step, new_ndcg, new_auc)\n",
        "        print(st)\n",
        "        f.write(st + '\\n')\n",
        "        f.flush()\n",
        "\n",
        "    step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llCp1DIPUTgo",
        "outputId": "8c69dc3b-ca4d-4ca0-adfe-84519352af33"
      },
      "source": [
        "for test_idx in range(len(os.listdir(refset_iri_dir))):\n",
        "  run(test_idx)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}